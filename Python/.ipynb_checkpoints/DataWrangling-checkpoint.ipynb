{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark\n",
    "\n",
    "I use this notebook firts to make some knowledge about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-LQK2FTR:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Wrangling Data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e1f4db9108>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Setting SparkSession:\n",
    "\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"Wrangling Data\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset files:\n",
    "|\n",
    "\n",
    "|--> Item information\n",
    "\n",
    "|\n",
    "\n",
    "|--> Station information\n",
    "\n",
    "|\n",
    "\n",
    "|--> Measurement info\n",
    "\n",
    "|\n",
    "\n",
    "|--> Measurement Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_item_file  = os.path.join('Resources', \"Data_Measurement_item_info.csv\")\n",
    "measurement_station_file  = os.path.join('Resources', \"Data_Measurement_station_info.csv\")\n",
    "measurement_info_file  = os.path.join('Resources', \"Measurement_info.csv\")\n",
    "measurement_file  = os.path.join('Resources', \"Measurement_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_item_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item code: string (nullable = true)\n",
      " |-- Item name: string (nullable = true)\n",
      " |-- Unit of measurement: string (nullable = true)\n",
      " |-- Good(Blue): string (nullable = true)\n",
      " |-- Normal(Green): string (nullable = true)\n",
      " |-- Bad(Yellow): string (nullable = true)\n",
      " |-- Very bad(Red): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_info.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Station code: string (nullable = true)\n",
      " |-- Station name(district): string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "station_info = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_station_file)\n",
    "station_info.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Measurement date: string (nullable = true)\n",
      " |-- Station code: string (nullable = true)\n",
      " |-- Item code: string (nullable = true)\n",
      " |-- Average value: string (nullable = true)\n",
      " |-- Instrument status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_info_file)\n",
    "info.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurament dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Measurement date: string (nullable = true)\n",
      " |-- Station code: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- SO2: string (nullable = true)\n",
      " |-- NO2: string (nullable = true)\n",
      " |-- O3: string (nullable = true)\n",
      " |-- CO: string (nullable = true)\n",
      " |-- PM10: string (nullable = true)\n",
      " |-- PM2.5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measurament = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_file)\n",
    "measurament.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------------+----------+-----------+-----+-----+-----+---+----+-----+\n",
      "|Measurement date|Station code|             Address|  Latitude|  Longitude|  SO2|  NO2|   O3| CO|PM10|PM2.5|\n",
      "+----------------+------------+--------------------+----------+-----------+-----+-----+-----+---+----+-----+\n",
      "|2017-01-01 00:00|         101|19, Jong-ro 35ga-...|37.5720164|127.0050075|0.004|0.059|0.002|1.2|73.0| 57.0|\n",
      "|2017-01-01 01:00|         101|19, Jong-ro 35ga-...|37.5720164|127.0050075|0.004|0.058|0.002|1.2|71.0| 59.0|\n",
      "|2017-01-01 02:00|         101|19, Jong-ro 35ga-...|37.5720164|127.0050075|0.004|0.056|0.002|1.2|70.0| 59.0|\n",
      "|2017-01-01 03:00|         101|19, Jong-ro 35ga-...|37.5720164|127.0050075|0.004|0.056|0.002|1.2|70.0| 58.0|\n",
      "|2017-01-01 04:00|         101|19, Jong-ro 35ga-...|37.5720164|127.0050075|0.003|0.051|0.002|1.2|69.0| 61.0|\n",
      "+----------------+------------+--------------------+----------+-----------+-----+-----+-----+---+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measurament.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+----------+-------------+-----------+-------------+\n",
      "|Item code|Item name|Unit of measurement|Good(Blue)|Normal(Green)|Bad(Yellow)|Very bad(Red)|\n",
      "+---------+---------+-------------------+----------+-------------+-----------+-------------+\n",
      "|        1|      SO2|                ppm|      0.02|         0.05|       0.15|          1.0|\n",
      "|        3|      NO2|                ppm|      0.03|         0.06|        0.2|          2.0|\n",
      "|        5|       CO|                ppm|       2.0|          9.0|       15.0|         50.0|\n",
      "|        6|       O3|                ppm|      0.03|         0.09|       0.15|          0.5|\n",
      "|        8|     PM10|      Mircrogram/m3|      30.0|         80.0|      150.0|        600.0|\n",
      "|        9|    PM2.5|      Mircrogram/m3|      15.0|         35.0|       75.0|        500.0|\n",
      "+---------+---------+-------------------+----------+-------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info - Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class equipament:\n",
    "    \n",
    "    def __init__(self, code,name,unit,level1,level2,level3,level4):\n",
    "        self.code = code\n",
    "        self.name = name\n",
    "        self.unit = unit\n",
    "        self.good = float(level1)\n",
    "        self.normal = float(level2)\n",
    "        self.bad = float(level3)\n",
    "        self.veryBad = float(level4)\n",
    "        self.color = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getLevel(self,value):\n",
    "        if value < self.good:\n",
    "            self.color = 1\n",
    "            return (\"Good\")\n",
    "        elif value < self.normal:\n",
    "            self.color = 2\n",
    "            return (\"Normal\")\n",
    "        elif value < self.bad:\n",
    "            self.color = 3\n",
    "            return (\"Bad\")\n",
    "        elif value < self.veryBad:\n",
    "            self.color = 4\n",
    "            return (\"Very Bad\")\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return(f\"Equipament Code = {str(self.code)}, Name = {str(self.name)}, Unit of Measurement = {str(self.unit)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = item_info.toPandas()\n",
    "\n",
    "list_equipaments = [equipament(row[0],row[1],row[2],row[3],row[4],row[5],row[6]) for index,row in item_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SO2': Equipament Code = 1, Name = SO2, Unit of Measurement = ppm,\n",
       " 'NO2': Equipament Code = 3, Name = NO2, Unit of Measurement = ppm,\n",
       " 'CO': Equipament Code = 5, Name = CO, Unit of Measurement = ppm,\n",
       " 'O3': Equipament Code = 6, Name = O3, Unit of Measurement = ppm,\n",
       " 'PM10': Equipament Code = 8, Name = PM10, Unit of Measurement = Mircrogram/m3,\n",
       " 'PM2.5': Equipament Code = 9, Name = PM2.5, Unit of Measurement = Mircrogram/m3}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equipaments = {\n",
    "    \"SO2\": list_equipaments[0],\n",
    "    \"NO2\": list_equipaments[1],\n",
    "    \"CO\": list_equipaments[2],\n",
    "    \"O3\": list_equipaments[3],\n",
    "    \"PM10\": list_equipaments[4],\n",
    "    \"PM2.5\": list_equipaments[5]\n",
    "}\n",
    "equipaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "equipaments[\"SO2\"].getLevel(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify The Color Level of each measurement info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the level Risk for SO2\n",
    "level_risk = udf(lambda x: equipaments[\"SO2\"].getLevel(float(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a Type of Equipament Measurement\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "recent_measurements = measurament.select([col(\"SO2\").alias(\"SO2\"),col(\"Measurement date\")\n",
    "                                          (F.regexp_extract('Measurement date',r'2017-01-01*', 0)).alias(\"DataNow\")\n",
    "                                         ])\n",
    "\n",
    "# Adding a column with Level Risk\n",
    "\n",
    "\n",
    "measurement_info_risk = recent_measurements.withColumn(\"Level\", level_risk(\"SO2\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SO2='0.004', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.004', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.004', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.004', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.003', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.003', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.003', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.003', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.004', DataNow='2017-01-01', Level='Good'),\n",
       " Row(SO2='0.003', DataNow='2017-01-01', Level='Good')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_info_risk.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Question There is any Bad or Very Bad level in 2017-01-01, for SO2 , check This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurament_now = measurament.select([\"SO2\",\"Measurement date\",\"Station code\"]) \\\n",
    "                            .filter(measurament[\"Measurement date\"].rlike(\"2017-01-01*\")) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+------------+-----+\n",
      "|  SO2|Measurement date|Station code|Level|\n",
      "+-----+----------------+------------+-----+\n",
      "|0.004|2017-01-01 00:00|         101| Good|\n",
      "|0.004|2017-01-01 01:00|         101| Good|\n",
      "|0.004|2017-01-01 02:00|         101| Good|\n",
      "|0.004|2017-01-01 03:00|         101| Good|\n",
      "|0.003|2017-01-01 04:00|         101| Good|\n",
      "|0.003|2017-01-01 05:00|         101| Good|\n",
      "|0.003|2017-01-01 06:00|         101| Good|\n",
      "|0.003|2017-01-01 07:00|         101| Good|\n",
      "|0.004|2017-01-01 08:00|         101| Good|\n",
      "|0.003|2017-01-01 09:00|         101| Good|\n",
      "|0.004|2017-01-01 10:00|         101| Good|\n",
      "|0.004|2017-01-01 11:00|         101| Good|\n",
      "|0.004|2017-01-01 12:00|         101| Good|\n",
      "|0.005|2017-01-01 13:00|         101| Good|\n",
      "|0.006|2017-01-01 14:00|         101| Good|\n",
      "|0.006|2017-01-01 15:00|         101| Good|\n",
      "|0.006|2017-01-01 16:00|         101| Good|\n",
      "|0.005|2017-01-01 17:00|         101| Good|\n",
      "|0.005|2017-01-01 18:00|         101| Good|\n",
      "|0.005|2017-01-01 19:00|         101| Good|\n",
      "+-----+----------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measurament_now = measurament_now.withColumn(\"Level\", level_risk(\"SO2\"))\n",
    "measurament_now.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of Bad ocurrence = 2 and Numbers of Very Bad ocurrence = 0\n"
     ]
    }
   ],
   "source": [
    "bad_ocurence = measurament_now.filter(measurament_now[\"Level\"] == \"Bad\").count()\n",
    "very_bad_occurence = measurament_now.filter(measurament_now[\"Level\"] == \"Very Bad\").count()\n",
    "\n",
    "print(f\"Numbers of Bad ocurrence = {bad_ocurence} and Numbers of Very Bad ocurrence = {very_bad_occurence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
