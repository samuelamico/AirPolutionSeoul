{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-LQK2FTR:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Bulk-Data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x16c147c7fc8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create Spark-Session\n",
    "\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"Bulk-Data\") \\\n",
    "            .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files = r'C:\\Users\\samfs\\Desktop\\Projetos-Samuel\\AirPolutionSeoul\\Python\\Resources'\n",
    "\n",
    "measurement_item_file  = os.path.join(path_files, \"Data_Measurement_item_info.csv\")\n",
    "measurement_station_file  = os.path.join(path_files, \"Data_Measurement_station_info.csv\")\n",
    "measurement_info_file  = os.path.join(path_files, \"Measurement_info.csv\")\n",
    "measurement_file  = os.path.join(path_files, \"Measurement_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+----------+-------------+-----------+-------------+\n",
      "|Item code|Item name|Unit of measurement|Good(Blue)|Normal(Green)|Bad(Yellow)|Very bad(Red)|\n",
      "+---------+---------+-------------------+----------+-------------+-----------+-------------+\n",
      "|        1|      SO2|                ppm|      0.02|         0.05|       0.15|          1.0|\n",
      "|        3|      NO2|                ppm|      0.03|         0.06|        0.2|          2.0|\n",
      "+---------+---------+-------------------+----------+-------------+-----------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Read the Files:\n",
    "\n",
    "item_info = spark.read.format('csv').option('header','true').load(measurement_item_file)\n",
    "item_info.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+--------------------+------------------+------------------+\n",
      "|Station code|Station name(district)|             Address|          Latitude|         Longitude|\n",
      "+------------+----------------------+--------------------+------------------+------------------+\n",
      "|         101|             Jongno-gu|19, Jong-ro 35ga-...|37.572016399999995|127.00500749999999|\n",
      "|         102|               Jung-gu|15, Deoksugung-gi...|37.564262899999996|126.97467569999999|\n",
      "+------------+----------------------+--------------------+------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "station_file = spark.read.format('csv').option('header','true').load(measurement_station_file)\n",
    "station_file.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+---------+--------------------+-----------------+\n",
      "|Measurement date|Station code|Item code|       Average value|Instrument status|\n",
      "+----------------+------------+---------+--------------------+-----------------+\n",
      "|2017-01-01 00:00|         101|        1|               0.004|                0|\n",
      "|2017-01-01 00:00|         101|        3|0.059000000000000004|                0|\n",
      "+----------------+------------+---------+--------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info_file = spark.read.format('csv').option('header','true').load(measurement_info_file)\n",
    "info_file.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------------+----------+-----------+-----+-----+-----+---+----+-----+\n",
      "|Measurement date|Station code|             Address|  Latitude|  Longitude|  SO2|  NO2|   O3| CO|PM10|PM2.5|\n",
      "+----------------+------------+--------------------+----------+-----------+-----+-----+-----+---+----+-----+\n",
      "|2017-01-01 00:00|         101|19, Jong-ro 35ga-...|37.5720164|127.0050075|0.004|0.059|0.002|1.2|73.0| 57.0|\n",
      "|2017-01-01 01:00|         101|19, Jong-ro 35ga-...|37.5720164|127.0050075|0.004|0.058|0.002|1.2|71.0| 59.0|\n",
      "+----------------+------------+--------------------+----------+-----------+-----+-----+-----+---+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measurement = spark.read.format('csv').option('header','true').load(measurement_file)\n",
    "measurement.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equipament class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class equipament:\n",
    "    \n",
    "    def __init__(self, code,name,unit,level1,level2,level3,level4):\n",
    "        self.code = code\n",
    "        self.name = name\n",
    "        self.unit = unit\n",
    "        self.good = float(level1)\n",
    "        self.normal = float(level2)\n",
    "        self.bad = float(level3)\n",
    "        self.veryBad = float(level4)\n",
    "        self.color = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getLevel(self,value):\n",
    "        if value < self.good:\n",
    "            self.color = 1\n",
    "            return (\"Good\")\n",
    "        elif value < self.normal:\n",
    "            self.color = 2\n",
    "            return (\"Normal\")\n",
    "        elif value < self.bad:\n",
    "            self.color = 3\n",
    "            return (\"Bad\")\n",
    "        elif value < self.veryBad:\n",
    "            self.color = 4\n",
    "            return (\"Very Bad\")\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return(f\"Equipament Code = {str(self.code)}, Name = {str(self.name)}, Unit of Measurement = {str(self.unit)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = item_info.toPandas()\n",
    "\n",
    "list_equipaments = [equipament(row[0],row[1],row[2],row[3],row[4],row[5],row[6]) for index,row in item_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SO2': Equipament Code = 1, Name = SO2, Unit of Measurement = ppm,\n",
       " 'NO2': Equipament Code = 3, Name = NO2, Unit of Measurement = ppm,\n",
       " 'CO': Equipament Code = 5, Name = CO, Unit of Measurement = ppm,\n",
       " 'O3': Equipament Code = 6, Name = O3, Unit of Measurement = ppm,\n",
       " 'PM10': Equipament Code = 8, Name = PM10, Unit of Measurement = Mircrogram/m3,\n",
       " 'PM2.5': Equipament Code = 9, Name = PM2.5, Unit of Measurement = Mircrogram/m3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equipaments = {\n",
    "    \"SO2\": list_equipaments[0],\n",
    "    \"NO2\": list_equipaments[1],\n",
    "    \"CO\": list_equipaments[2],\n",
    "    \"O3\": list_equipaments[3],\n",
    "    \"PM10\": list_equipaments[4],\n",
    "    \"PM2.5\": list_equipaments[5]\n",
    "}\n",
    "equipaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equipaments['SO2'].getLevel(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## udf functions\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "udf_risk_SO2 = udf(lambda x: equipaments['SO2'].getLevel(float(x)))\n",
    "udf_risk_NO2 = udf(lambda x: equipaments['NO2'].getLevel(float(x)))\n",
    "udf_risk_CO = udf(lambda x: equipaments['CO'].getLevel(float(x)))\n",
    "udf_risk_O3 = udf(lambda x: equipaments['O3'].getLevel(float(x)))\n",
    "udf_risk_PM10 = udf(lambda x: equipaments['PM10'].getLevel(float(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_measurements = measurement.withColumn(\"Level_SO2\",udf_risk_SO2(\"SO2\")) \\\n",
    "                                    .withColumn(\"Level_NO2\",udf_risk_NO2(\"NO2\")) \\\n",
    "                                    .withColumn(\"Level_CO\",udf_risk_CO(\"CO\")) \\\n",
    "                                    .withColumn(\"Level_O3\",udf_risk_O3(\"O3\")) \\\n",
    "                                    .withColumn(\"Level_PM10\",udf_risk_PM10(\"PM10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'toList'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-850956e8d780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomplete_measurements_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplete_measurements\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'toList'"
     ]
    }
   ],
   "source": [
    "complete_measurements_list = complete_measurements.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Measurement date='2017-01-01 01:00', Station code='101', Address='19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republic of Korea', Latitude='37.5720164', Longitude='127.0050075', SO2='0.004', NO2='0.058', O3='0.002', CO='1.2', PM10='71.0', PM2.5='59.0', Level_SO2='Good', Level_NO2='Normal', Level_CO='Good', Level_O3='Good', Level_PM10='Normal')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complete_measurements_list)\n",
    "complete_measurements_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'localhost', 'port': 9200}])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "es = Elasticsearch(\"localhost:9200\")\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert to Bulk-JSON\n",
    "id_cont = 0\n",
    "actions = []\n",
    "\n",
    "for row in complete_measurements_list:\n",
    "    action = {\n",
    "        \"_index\": \"seoul_measurements\",\n",
    "        \"_id\": id_cont,\n",
    "        \"_source\": {\n",
    "              \"timestamp\": row[0],\n",
    "              \"station_code\": int(row[1]),\n",
    "              \"address\": row[2],\n",
    "              \"coordinate\": {\"lat\": float(row[3]),\"lon\": float(row[4])},\n",
    "              \"SO2\": float(row[5]),\n",
    "              \"NO2\": float(row[6]),\n",
    "              \"O3\": float(row[7]),\n",
    "              \"CO\": float(row[8]),\n",
    "              \"PM10\": float(row[9]),\n",
    "              \"Level_SO2\": str(row[10]),\n",
    "              \"Level_NO2\": str(row[11]),\n",
    "              \"Level_O3\": str(row[12]),\n",
    "              \"Level_CO\": str(row[13]),\n",
    "              \"Level_PM10\": str(row[14])\n",
    "            }\n",
    "        }\n",
    "    actions.append(action)\n",
    "    id_cont += 1\n",
    "\n",
    "helpers.bulk(es, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
