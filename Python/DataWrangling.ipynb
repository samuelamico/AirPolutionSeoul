{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark\n",
    "\n",
    "I use this notebook firts to make some knowledge about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-LQK2FTR:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Wrangling Data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fa229ea188>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Setting SparkSession:\n",
    "\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"Wrangling Data\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset files:\n",
    "|\n",
    "\n",
    "|--> Item information\n",
    "\n",
    "|\n",
    "\n",
    "|--> Station information\n",
    "\n",
    "|\n",
    "\n",
    "|--> Measurement info\n",
    "\n",
    "|\n",
    "\n",
    "|--> Measurement Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_item_file  = os.path.join('Resources', \"Data_Measurement_item_info.csv\")\n",
    "measurement_station_file  = os.path.join('Resources', \"Data_Measurement_station_info.csv\")\n",
    "measurement_info_file  = os.path.join('Resources', \"Measurement_info.csv\")\n",
    "measurement_file  = os.path.join('Resources', \"Measurement_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_item_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item code: string (nullable = true)\n",
      " |-- Item name: string (nullable = true)\n",
      " |-- Unit of measurement: string (nullable = true)\n",
      " |-- Good(Blue): string (nullable = true)\n",
      " |-- Normal(Green): string (nullable = true)\n",
      " |-- Bad(Yellow): string (nullable = true)\n",
      " |-- Very bad(Red): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_info.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Station code: string (nullable = true)\n",
      " |-- Station name(district): string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "station_info = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_station_file)\n",
    "station_info.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Measurement date: string (nullable = true)\n",
      " |-- Station code: string (nullable = true)\n",
      " |-- Item code: string (nullable = true)\n",
      " |-- Average value: string (nullable = true)\n",
      " |-- Instrument status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_info_file)\n",
    "info.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurament dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Measurement date: string (nullable = true)\n",
      " |-- Station code: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- SO2: string (nullable = true)\n",
      " |-- NO2: string (nullable = true)\n",
      " |-- O3: string (nullable = true)\n",
      " |-- CO: string (nullable = true)\n",
      " |-- PM10: string (nullable = true)\n",
      " |-- PM2.5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measurament = spark.read.format(\"csv\").option(\"header\", \"true\").load(measurement_file)\n",
    "measurament.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
